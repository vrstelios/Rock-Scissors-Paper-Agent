# -*- coding: utf-8 -*-
"""stylianos_verros_166_Rock-Scissors-Paper Agent.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SCeLjpJnx-GzJIpgiMHQpb8xm2fsm_rG

# My NAME
"""

NAME = "stylianos verros"

"""# Rock-Scissors-Paper-Agent

# Import Libraries
"""

import os
import cv2
import random
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras import layers, models
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import load_img, img_to_array

"""# Load Data"""

from google.colab import drive
drive.mount('/content/drive')

pathData = "/content/drive/MyDrive/Colab Notebooks/rps-cv-images"

moves = []
fileWithFigure = []
total_reward = 0
round_rewards = []

# Scan file rps_cv-images.
for folder in os.listdir(pathData):
    path = os.path.join(pathData, folder)

    if os.path.isdir(path):
        # Scan files paper, rock and scissors.
        for file in os.listdir(path):
            filePath = os.path.join(path, file)
            # Save the name of folder
            fileWithFigure.append(filePath)

            if folder.lower() == 'rock':
                moves.append(0)
            elif folder.lower() == 'paper':
                moves.append(1)
            elif folder.lower() == 'scissors':
                moves.append(2)

df = pd.DataFrame({'file figure': fileWithFigure, 'move': moves})

"""# Dataset and Dataloader"""

class ImageProcessingLayer(layers.Layer):
    def __init__(self, noise_mean, noise_std, brightness_factor, apply_filter):
        super(ImageProcessingLayer, self).__init__()
        self.pFlip = 0.5
        self.pHorizontalFlip = 0.5
        self.noise_mean = noise_mean
        self.noise_std = noise_std
        self.brightness_factor = brightness_factor
        self.apply_filter = apply_filter

    def call(self, inputs):
        # Apply image processing techniques to each input image
        processed_images = []
        for image in inputs:
            processed_image = preprocessImage(image, (30, 30), self.noise_mean, self.noise_std, self.brightness_factor, self.apply_filter)
            processed_images.append(processed_image)
        return tf.convert_to_tensor(processed_images)

noise_mean = 0
noise_std = 255 * 0.05
brightness_factor = 1.0
apply_filter = False

image_processing_layer = ImageProcessingLayer(noise_mean, noise_std, brightness_factor, apply_filter)

"""# Split data into train/test"""

# Now we will split our data to train and test!
train_set, test_set = train_test_split(df, test_size=0.2, stratify=df['move'], random_state=0)

"""# Build the model"""

# Pre-processing of training images.
X_train = np.array([preprocessImage(imagePath, (30, 30), 0, 255 * 0.05) for imagePath in train_set['file figure']])
X_train = X_train.reshape(X_train.shape[0], -1)

# Definition of the model CNN
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(30, 30, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(128, activation='relu'))
model.add(layers.Dense(3, activation='softmax'))

# Definition of the training process
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Training the model with the training data
X_train_cnn = X_train.reshape((X_train.shape[0], 30, 30, 1))
model.fit(X_train_cnn, train_set['move'], epochs = 10, batch_size = 32, validation_split = 0.2)

"""# Build the random Agent"""

def randomSelectImage(images_per_move=700):
    # random settlement movements (0, 1, ή 2)
    move = np.random.choice([0, 1, 2])
    moveImage = df[df['move'] == move].sample(images_per_move, replace=True)
    # random image selection
    selectedImage = moveImage.sample(1)

    return selectedImage['file figure'].values[0], move


selectedImage, move = randomSelectImage()

def preprocessImage(imagePath):
    image = load_img(imagePath, target_size=(30, 30), color_mode='grayscale')
    image = img_to_array(image)

    # Normalization
    image = image / 255.0

    # Adjust brightness
    image = cv2.convertScaleAbs(image, alpha =  1.0, beta = 0)

    # Apply filter if specified
    if False:
        image = cv2.GaussianBlur(image, (5, 5), 0)  # Example: Gaussian Blur

    # Vertical Flip application with probability pFlip
    if np.random.rand() < 0.5:
        image = cv2.flip(image, 0)

    # Horizontal Flip application with probability pHorizontalFlip
    if np.random.rand() < 0.5:
        image = cv2.flip(image, 1)

    # Add noise to the image
    noise = np.random.normal(0, 0.05, image.shape)
    image = np.clip(image + noise, 0, 1)

    return image

def get_agent_action(image):
    preproImage = preprocessImage(image)

    # Application to the model for prediction
    preprocessedImage_cnn = preproImage.reshape((1, 30, 30, 1))
    prediction = model.predict(preprocessedImage_cnn)

    return np.argmax(prediction)

"""# Play the game"""

totalReward = 0
roundRewards = []
countLose = 0
countWin = 0
N = 100
for _ in range(N):
    winAgent = False
    loseAgent = False
    currentRoundReward = 1

    while not (winAgent or loseAgent):
        # Random motion selection for the Random Agent
        imageRandomAgent, moveRandomAgent = randomSelectImage()
        # Movement of the agent
        moveAgent = get_agent_action(imageRandomAgent)
        # bet
        currentRoundReward -= 1

        # Check for which move wins
        if (moveRandomAgent + 1) % 3 == moveAgent:
            currentRoundReward += 2
            countWin += 1
            winAgent = True
        elif moveRandomAgent == moveAgent:
            currentRoundReward += 1
        else:
            loseAgent = True
            countLose += 1

        # print(currentRoundReward, winAgent, loseAgent)
        totalReward += currentRoundReward
        roundRewards.append(totalReward)

## print(totalReward)
print("winning rate", (countWin / N) * 100)
print("Rate of defeats", (countLose / N) * 100)

# show plot
plt.plot(roundRewards)
plt.xlabel('Round')
plt.ylabel('Total Profit')
plt.title('Total Profit per Round')
plt.show()

"""# Test it in other images"""

# Function to display images and their corresponding noise
def display_images_with_noise(image_paths, noise_mean, noise_std):
    num_images_to_display = 3
    random_image_paths = random.sample(image_paths, num_images_to_display)

    for image_path in random_image_paths:
        # Original Image
        original_image = cv2.imread(image_path)
        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)

        # Processed Image
        processed_image = preprocessImage(image_path, (30, 30), noise_mean, noise_std)

        # Display Original Image
        plt.figure(figsize=(8, 4))
        plt.subplot(1, 2, 1)
        plt.imshow(original_image)
        plt.title('Original Image')
        plt.axis('off')

        # Display Processed Image
        plt.subplot(1, 2, 2)
        plt.imshow(processed_image, cmap='gray')  # Assuming processed_image is grayscale
        plt.title('Processed Image with Noise')
        plt.axis('off')

        plt.show()

# Display some images with their corresponding noise
display_images_with_noise(train_set['file figure'].tolist(),noise_mean=0, noise_std=255 * 0.05)

"""# Get model predictions for Web Images"""

# Load the image
new_image_path = ('/content/drive/MyDrive/Colab Notebooks/rps-cv-images/scissors/0CSaM2vL2cWX6Cay.png')

# Pre-processing of the new image
preprocessed_new_image = preprocessImage(new_image_path, (30, 30), 0, 255 * 0.05,)

preprocessedImage_cnn = preprocessed_new_image.reshape((1, 30, 30, 1))
prediction_for_new_image = model.predict(preprocessedImage_cnn)

if np.argmax(prediction_for_new_image) == 0:
    print("Predicted Move - Rock")
elif np.argmax(prediction_for_new_image) == 1:
    print("Predicted Move - Scissors")
elif np.argmax(prediction_for_new_image) == 2:
    print("Predicted Move - Paper")

"""# Answers

## Experiment with various models, image processing methods, techniques to improve the accuracy of models/agents, etc. You can submit the exercise using only one model/agent, but justify why you chose it (e.g., I chose it because it seems to have a performance of 99%).

**Convolutional Neural Networks (CNNs)** owe their ability to understand the structure of images and effectively handle tasks such as object recognition, and in the specific case, games like rock-paper-scissors.

In comparison to other classifiers such as Multi-Layer Perceptron (MLP) or K-Nearest Neighbors (KNN), which are more suitable for data structures like matrices, CNNs have the capability to perceive patterns and features that are in close proximity of image elements, making them ideal for image processing problems.

In summary, the CNN's performance with a 62% win rate seems satisfactory compared to other classifiers, making it a suitable choice for the problem at hand.

## Analysis of the final solution reveals its performance across different categories of images:

The **Convolutional Neural Networks (CNN)** performed exceptionally well in classifying the "Rock" images. However, it occasionally misclassified the "Scissors" images, especially when the fingers in the black silhouette were not clearly visible, often confusing them with "Paper" images. Similarly, it frequently misidentified "Paper" images as "Scissors," facing the same issue with the clarity of the silhouettes.

The primary parameter affecting the model's performance is the amount of noise present in the images. In my implementation, a noise level of 0.01 yielded the best results. Additionally, adjusting the brightness level is crucial for enhancing the contrast between black and white colors to improve silhouette distinction.

# Justify the models and techniques you chose, as well as your performance.

For Ν = 100
#Convolutional Neural Network (CNN)
winning rate 62.0, Rate of defeats 38.0
#Multi-Layer Perceptron (MLP)
winning rate 54.0, Rate of defeats 46.0
#K-Nearest Neighbors (KNN):
winning rate 41.0, Rate of defeats 59.0

**Convolutional Neural Networks (CNN):**
Usage: Ideal for images. Extremely effective for feature extraction and classification..

**K-Nearest Neighbors (KNN)**
User: Compared to the simple MLP, the CNN architecture is superior as it filters groups of pixels..

**Multi-Layer Perceptron (MLP)**
Usage: Suitable for various nonlinear classification and regression problems. It is flexible and suitable for problems where the relationships between features are complex.
"""